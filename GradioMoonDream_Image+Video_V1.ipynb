{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0726bf7b-b5f7-4829-8b69-c5c34b366ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (4.26.0)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Downloading scikit_image-0.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting timm\n",
      "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.110.1)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.15.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.7.0)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (0.12.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.13.0)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (68.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.2.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (13.7.1)\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (0.1.2)\n",
      "Downloading scikit_image-0.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Downloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110721 sha256=e09f1a28cf06d2120512c6b8d7984ed7a5fe7ab34829aaee6610a40486f91ac3\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\n",
      "Successfully built moviepy\n",
      "Installing collected packages: tifffile, proglog, lazy-loader, imageio_ffmpeg, imageio, einops, decorator, scikit-image, moviepy, timm\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 einops-0.7.0 imageio-2.34.0 imageio_ffmpeg-0.4.9 lazy-loader-0.4 moviepy-1.0.3 proglog-0.1.10 scikit-image-0.23.1 tifffile-2024.2.12 timm-0.9.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers pillow numpy gradio moviepy scikit-image timm einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b74dcfe-2c5a-4a54-8b32-1b1e55e3593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from moviepy.editor import VideoFileClip\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import datetime\n",
    "import gradio as gr\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fab324b0-645c-44b7-913d-8de06527416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "\n",
    "uploaded_image_path = None\n",
    "\n",
    "def extract_predictions(model_output):\n",
    "    probas = model_output.logits.softmax(-1)[0, :, :-1].cpu().detach().numpy()\n",
    "    keep = probas.max(-1) > 0.4\n",
    "    boxes = model_output.pred_boxes[0, keep].cpu().detach().numpy()\n",
    "    scores = probas[keep].max(-1)\n",
    "    labels = probas[keep].argmax(-1)\n",
    "    return [(box, score, label) for box, score, label in zip(boxes, scores, labels)]\n",
    "\n",
    "def perform_object_detection(image):\n",
    "    feature_extractor, detector = (DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\"),\n",
    "                                   DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(device))\n",
    "    \n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
    "    outputs = detector(**inputs)\n",
    "    predictions = extract_predictions(outputs)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def save_image_data_to_file(image_path, caption, predictions, responses):\n",
    "    folder_name = \"moondream_responses\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    image_name = os.path.basename(image_path)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    file_name = f\"{image_name}_{timestamp}.txt\"\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(f\"Image: {image_name}\\n\")\n",
    "        file.write(f\"Caption: {caption}\\n\")\n",
    "        file.write(\"Objects Detected:\\n\")\n",
    "        for _, score, label in predictions:\n",
    "            file.write(f\"- {coco_names[label]} ({score:.2f})\\n\")\n",
    "        file.write(\"\\nMoondream Responses:\\n\")\n",
    "        for i, response in enumerate(responses):\n",
    "            file.write(f\"Question {i+1}: {response[0]}\\n\")\n",
    "            file.write(f\"Answer {i+1}: {response[1]}\\n\\n\")\n",
    "    \n",
    "    print(f\"Image data saved to the file '{file_path}'.\")\n",
    "\n",
    "def process_image(image, caption, habit):\n",
    "    global uploaded_image_path\n",
    "    image_path = \"uploaded_image.jpg\"\n",
    "    image.save(image_path)\n",
    "    uploaded_image_path = image_path\n",
    "    \n",
    "    predictions = perform_object_detection(image)\n",
    "    \n",
    "    questions = [\n",
    "        \"Describe the color and ambience of the image.\",\n",
    "        f\"What objects in the image are good or bad for the {habit}?\",\n",
    "        f\"Based on the {caption}, Please provide suggestions that will help the user in maintaining their {habit}.\",\n",
    "    ]\n",
    "    \n",
    "    responses = []\n",
    "    for question in questions:\n",
    "        answer = moondream_chatbot(question)\n",
    "        responses.append((question, answer))\n",
    "    \n",
    "    save_image_data_to_file(image_path, caption, predictions, responses)\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def moondream_chatbot(user_input):\n",
    "    global uploaded_image_path\n",
    "    model_id = \"vikhyatk/moondream2\"\n",
    "    revision = \"2024-03-05\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision).to(\"cuda\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "\n",
    "    if uploaded_image_path is not None:\n",
    "        image = Image.open(uploaded_image_path)\n",
    "        enc_image = model.encode_image(image).to(\"cuda\")\n",
    "        answer = model.answer_question(enc_image, user_input, tokenizer)\n",
    "    else:\n",
    "        answer = \"Please upload an image first.\"\n",
    "\n",
    "    if isinstance(answer, torch.Tensor):\n",
    "        answer = answer.cpu()\n",
    "    \n",
    "    save_chat_history(user_input, answer)\n",
    "    \n",
    "    return [(user_input, answer)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "922567cc-beb1-477e-85ab-dd1df57ee15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path):\n",
    "    print(\"Extracting frames from the video...\")\n",
    "    frames = []\n",
    "    clip = VideoFileClip(video_path)\n",
    "    for frame in clip.iter_frames():\n",
    "        frame = Image.fromarray(frame)\n",
    "        frames.append(frame)\n",
    "    clip.close()\n",
    "    print(\"Frame extraction completed.\")\n",
    "    return frames\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def is_similar(frame1, frame2, threshold=0.9):\n",
    "    # Convert frames to grayscale\n",
    "    frame1_gray = frame1.convert('L')\n",
    "    frame2_gray = frame2.convert('L')\n",
    "    \n",
    "    # Calculate structural similarity index (SSIM)\n",
    "    similarity = ssim(np.array(frame1_gray), np.array(frame2_gray))\n",
    "    \n",
    "    return similarity > threshold\n",
    "\n",
    "def process_video(video_path, text_prompt, habit, caption, model, tokenizer):\n",
    "    print(\"Processing the video...\")\n",
    "    frames = extract_frames(video_path)\n",
    "    frame_rate = len(frames) // 20  # Assuming 5-second video\n",
    "    responses = []\n",
    "    prev_frame = None\n",
    "\n",
    "    questions = [\n",
    "        f\"Based on the {caption}, Please provide suggestions that will help the user in maintaining their {habit}.\",\n",
    "        \"Specify as many objects with their relative location that are present in the image.\",\n",
    "        \"Describe the color and ambience and lighting conditions in the image.\",\n",
    "        f\"How does the image relate to or impact the {habit}?\"\n",
    "    ]\n",
    "\n",
    "    for i in range(0, len(frames), frame_rate):\n",
    "        frame = frames[i]\n",
    "        print(f\"Processing frame {i}...\")\n",
    "        \n",
    "        if prev_frame is not None:\n",
    "            print(\"Comparing frame similarity...\")\n",
    "            if is_similar(frame, prev_frame, threshold=0.7):\n",
    "                print(\"Frame is similar to the previous frame. Skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Frame is different from the previous frame.\")\n",
    "        \n",
    "        enc_image = model.encode_image(frame)\n",
    "        \n",
    "        question = questions[i // frame_rate % len(questions)]\n",
    "        response = model.answer_question(enc_image, question, tokenizer)\n",
    "        \n",
    "        # Add image tag and time to the response\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        response_with_tag = f\"[Frame {i}] [{current_time}] {response}\"\n",
    "        \n",
    "        print(f\"Moondream output for frame {i}: {response_with_tag}\")\n",
    "        \n",
    "        responses.append(response_with_tag)\n",
    "        prev_frame = frame\n",
    "\n",
    "    print(\"Video processing completed.\")\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e6f58da-d23a-4e7e-8cbf-3f840408a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_responses_to_file(responses, video_path):\n",
    "    folder_name = \"moondream_responses\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    if len(responses) > 0:\n",
    "        video_name = os.path.basename(video_path)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        file_name = f\"video_{video_name}_{timestamp}.txt\"\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        \n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(f\"Video: {video_name}\\n\\n\")\n",
    "            for response in responses:\n",
    "                file.write(response + \"\\n\")\n",
    "        \n",
    "        print(f\"Video responses saved to the file '{file_path}'.\")\n",
    "    else:\n",
    "        print(\"No responses to save.\")\n",
    "\n",
    "def save_chat_history(user_input, response):\n",
    "    folder_name = \"moondream_responses\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(folder_name, \"chat_history.txt\")\n",
    "    \n",
    "    with open(file_path, \"a\") as file:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        file.write(f\"[{timestamp}] User: {user_input}\\n\")\n",
    "        file.write(f\"[{timestamp}] Moondream: {response}\\n\\n\")\n",
    "\n",
    "def process_image_upload(image_file, caption, habit):\n",
    "    global uploaded_image_path\n",
    "    if image_file is None:\n",
    "        return \"Please upload an image file.\", None\n",
    "    \n",
    "    image = Image.open(image_file.name)\n",
    "    responses = process_image(image, caption, habit)\n",
    "    \n",
    "    uploaded_image_path = image_file.name\n",
    "    \n",
    "    return \"Image processed successfully. Responses saved to file.\", uploaded_image_path\n",
    "\n",
    "def process_video_upload(video_file, text_prompt, habit, caption):\n",
    "    if video_file is None:\n",
    "        return \"Please upload a video file.\"\n",
    "    \n",
    "    video_path = video_file.name\n",
    "    \n",
    "    # Initialize the model and tokenizer\n",
    "    model_id = \"vikhyatk/moondream2\"\n",
    "    revision = \"2024-03-05\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision).to(\"cuda\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "    \n",
    "    responses = process_video(video_path, text_prompt, habit, caption, model, tokenizer)\n",
    "    save_video_responses_to_file(responses, video_path)\n",
    "    \n",
    "    return \"Video processed successfully. Responses saved to file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c5aa016-56a7-48d6-bc9f-e9738e4bf04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "Running on public URL: https://c25bc8fb85a4bfb574.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c25bc8fb85a4bfb574.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft(\n",
    "    primary_hue=\"blue\",\n",
    "    secondary_hue=\"blue\",\n",
    "    neutral_hue=\"gray\",\n",
    "    text_size=gr.themes.sizes.text_sm,\n",
    "    spacing_size=gr.themes.sizes.spacing_md,\n",
    "    radius_size=gr.themes.sizes.radius_md,\n",
    ")) as demo:\n",
    "    gr.Markdown(\"# Moondream Image and Video Processing App\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image_file = gr.File(label=\"Upload Image\")\n",
    "            video_file = gr.File(label=\"Upload Video\")\n",
    "            habit = gr.Textbox(label=\"Enter Habit\")\n",
    "            caption = gr.Textbox(label=\"Enter Caption\")\n",
    "            with gr.Row():\n",
    "                image_submit_button = gr.Button(\"Process Image\")\n",
    "                video_submit_button = gr.Button(\"Process Video\")\n",
    "        with gr.Column():\n",
    "            output_text = gr.Textbox(label=\"Output\")\n",
    "            image_chatbot = gr.Chatbot(label=\"Moondream Chatbot - Image\")\n",
    "            image_user_input = gr.Textbox(label=\"User Input - Image\")\n",
    "    \n",
    "    image_submit_button.click(process_image_upload, inputs=[image_file, caption, habit], outputs=[output_text])\n",
    "    video_submit_button.click(process_video_upload, inputs=[video_file, caption, habit, caption], outputs=[output_text])\n",
    "    \n",
    "    image_user_input.submit(moondream_chatbot, inputs=[image_user_input], outputs=[image_chatbot])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81ba6ece-9fe0-4716-98f7-a92dfc8c12ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7876\n",
      "Running on public URL: https://c463a39cca985c0fa7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c463a39cca985c0fa7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_upload(file):\n",
    "    if file is None:\n",
    "        return \"Please upload an image or video file.\", None\n",
    "    \n",
    "    if file.name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        # Process image\n",
    "        image = Image.open(file.name)\n",
    "        responses = process_image(image, caption, habit)\n",
    "        uploaded_image_path = file.name\n",
    "        return \"Image processed successfully. Responses saved to file.\", uploaded_image_path\n",
    "    elif file.name.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "        # Process video\n",
    "        video_path = file.name\n",
    "        model_id = \"vikhyatk/moondream2\"\n",
    "        revision = \"2024-03-05\"\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision).to(\"cuda\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "        responses = process_video(video_path, caption, habit, caption, model, tokenizer)\n",
    "        save_video_responses_to_file(responses, video_path)\n",
    "        return \"Video processed successfully. Responses saved to file.\", None\n",
    "    else:\n",
    "        return \"Unsupported file format. Please upload an image or video file.\", None\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(\n",
    "    primary_hue=\"blue\",\n",
    "    secondary_hue=\"blue\",\n",
    "    neutral_hue=\"gray\",\n",
    "    #background_fill=\"#F5F5F5\",  # Light gray background\n",
    "    text_size=gr.themes.sizes.text_sm,\n",
    "    spacing_size=gr.themes.sizes.spacing_md,\n",
    "    radius_size=gr.themes.sizes.radius_md,\n",
    ")) as demo:\n",
    "    gr.Markdown(\"# Moondream Image and Video Processing App\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file_upload = gr.File(label=\"Upload Image or Video\")\n",
    "            habit = gr.Textbox(label=\"Enter Habit\")\n",
    "            caption = gr.Textbox(label=\"Enter Caption\")\n",
    "            submit_button = gr.Button(\"Process\")\n",
    "        with gr.Column():\n",
    "            output_text = gr.Textbox(label=\"Output\")\n",
    "            image_chatbot = gr.Chatbot(label=\"Moondream Chatbot - Image\")\n",
    "            image_user_input = gr.Textbox(label=\"User Input - Image\")\n",
    "    \n",
    "    submit_button.click(process_upload, inputs=[file_upload], outputs=[output_text])\n",
    "    \n",
    "    image_user_input.submit(moondream_chatbot, inputs=[image_user_input], outputs=[image_chatbot])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de60e70-4347-4e6d-b574-713a522c0503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
